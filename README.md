# Embracing Sphere

Conveying a story through the environment is a known technique in multiple media domains. Blood stain under the door, footstep trails on snow and broken chains next to a beware dog sign; all those flash scene descriptions are an example for environmental storytelling. Heavy reliance on visual cues defines the limitations of current methods in environmental storytelling. Utilizing multi-modal stimuli and 3D audio volumes for enhancing environmental storytelling remains niche and open for new perspectives in storytelling and narration through the environment. 

This research explores the integration of haptic feedback and acoustic modeling methods. Haptic feedback systems mostly used by video games, racing simulations and interactive art installations and haptic signals are mostly vibrations that are transferred by low frequency audio signals to create pulses on haptic actuators. Complementing tactile experience, Room Impulse Responses (RIR) utilized as a method of capturing acoustic properties of an enclosed volume/space later to use in reverberation(specifically convolution reverbs) to reconstruct the same acoustic responses while simulating different materials. Combining these distinct modalities such as tactile pulses and acoustic simulations offer a novel way to represent environmental snapshots purely through non-visual interfaces.

Building on this potential, a multi-modal stimulation scenario using simultaneous audio signal playback driven by a speaker array incorporating procedurally generated RIRs and a bass shaker (transducer) will be this article's foundational practical method. 

This applied work investigates the current state and the potential of such multi-modal experiences in conveying environmental information. Proposed artwork designs, implements and evaluates an interactive audio-tactile system capabilities of procedurally generated environmental snapshots for storytelling purposes.

![Embracing Sphere Logo](images/logo_embrace_sphere.png "Embracing Sphere Logo")